{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c26553a5",
   "metadata": {},
   "source": [
    "Data Preprocessing: Scaling, Encoding, Normalization (with Scikit-learn)\n",
    "\n",
    "What is data preprocessing?\n",
    "- Data preprocessing transforms raw data into a clean and usable format.\n",
    "- It improves model performance and training speed.\n",
    "\n",
    "Common Tasks:\n",
    "- Handling missing values.\n",
    "- Scaling numerical features\n",
    "- Encoding categorical variables.\n",
    "- Normalizing feature ranges.\n",
    "\n",
    "1. Feature Scaling:\n",
    "    - Scaling adjusts values so features contribute equally.\n",
    "    - Common Techniques: StandardScaler (Z-score), MinMaxScaler (0-1 scale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "108f6da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Salary</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60000</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55000</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70000</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65000</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Salary  Age\n",
       "0   50000   25\n",
       "1   60000   30\n",
       "2   55000   28\n",
       "3   70000   35\n",
       "4   65000   32"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Example dataset\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'Salary': [50000, 60000, 55000, 70000, 65000],\n",
    "    'Age': [25, 30, 28, 35, 32]\n",
    "})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5a1364",
   "metadata": {},
   "source": [
    "- here as Salary values are bigger, Machine Learning model may think that Salary values have more importance as compared to Age values and give it more importance.\n",
    "\n",
    "- Machine learning will give higher importance to higher value columns.\n",
    "\n",
    "- As a data analyst, both are supposed to have equal importance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ffb8380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized Data:\n",
      "     Salary       Age\n",
      "0 -1.414214 -1.468051\n",
      "1  0.000000  0.000000\n",
      "2 -0.707107 -0.587220\n",
      "3  1.414214  1.468051\n",
      "4  0.707107  0.587220\n"
     ]
    }
   ],
   "source": [
    "# Standardization helps to center the data around zero with a standard deviation of one.\n",
    "# This is useful for algorithms that assume a Gaussian distribution of the data.\n",
    "# which makes model to give equal importance to all features.\n",
    "\n",
    "scaler_standard = StandardScaler()\n",
    "data_standardized = scaler_standard.fit_transform(data)\n",
    "data_standardized = pd.DataFrame(data_standardized, columns=data.columns)\n",
    "print(\"Standardized Data:\")\n",
    "print(data_standardized)\n",
    "# Now, data_standardized has a mean of 0 and a standard deviation of 1 for each feature.\n",
    "# and we cant say which feature has more importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4ff2b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_transform() does two things:\n",
    "# 1 fit(): It calculates the mean and standard deviation for each feature in the dataset.\n",
    "# 2 transform(): It uses these calculated values to standardize the dataset\n",
    " # applied scaling (converts data to Z-scores) in one step.\n",
    "\n",
    "    # Z-score formula: Z = (X - mean) / std_dev\n",
    "\n",
    "# For Standard Scaler: Each feature will have mean = 0 and standard deviation = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdcd6a5",
   "metadata": {},
   "source": [
    "#### Min-Max Scaling (0 to 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ce82cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Min-Max Scaled Data:\n",
      "   Salary  Age\n",
      "0    0.00  0.0\n",
      "1    0.50  0.5\n",
      "2    0.25  0.3\n",
      "3    1.00  1.0\n",
      "4    0.75  0.7\n"
     ]
    }
   ],
   "source": [
    "# Min-Max Scaling transforms features by scaling each feature to a given range, usually between 0 and 1.\n",
    "scaler_minmax = MinMaxScaler()\n",
    "data_minmax_scaled = scaler_minmax.fit_transform(data)\n",
    "data_minmax_scaled = pd.DataFrame(data_minmax_scaled, columns=data.columns)\n",
    "print(\"\\nMin-Max Scaled Data:\")\n",
    "print(data_minmax_scaled)\n",
    "# Now, data_minmax_scaled has values between 0 and 1 for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17f550c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here values are between 0 and 1.\n",
    "# how its calculated:\n",
    "# scaled_value = (X - min) / (max - min)\n",
    "# where X is the original value, min is the minimum value of the feature, and max is the maximum value of the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "672bc403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference between Standardization and Min-Max Scaling:\n",
    "# Standardization centers the data around zero with a standard deviation of one, while Min-Max Scaling scales the data to a fixed range, typically between 0 and 1.\n",
    "# Standardization is less affected by outliers compared to Min-Max Scaling.\n",
    "# Standardization don't have fixed range, while Min-Max Scaling always between 0 and 1.\n",
    "# --- IGNORE ---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e62af38",
   "metadata": {},
   "source": [
    "2. Encoding Categorical Variables\n",
    "\n",
    "Convert text labels to numeric format for ML Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3b05efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have 2 techniques for converting text labels into numerical form:\n",
    "# 1. Label Encoding\n",
    "# 2. One-Hot Encoding\n",
    "# --- IGNORE ---\n",
    "# label encoding assigns each unique category in a feature a unique integer value.\n",
    "# For example, in a \"Color\" feature with categories \"Red\", \"Blue\", and\n",
    "# \"Green\", label encoding might assign \"Red\" = 0, \"Blue\" = 1, and \"Green\" = 2.\n",
    "\n",
    "# One-Hot Encoding creates binary columns for each category in a feature.\n",
    "# Using the same \"Color\" feature example, one-hot encoding would create three new columns:\n",
    "# \"Color_Red\", \"Color_Blue\", and \"Color_Green\". Each row\n",
    "# would have a 1 in the column corresponding to its category and 0s in the others.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f2f211f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Color\n",
       "0    Red\n",
       "1   Blue\n",
       "2  Green\n",
       "3   Blue\n",
       "4    Red"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Example dataset with categorical feature\n",
    "data_cat = pd.DataFrame({  \n",
    "    'Color': ['Red', 'Blue', 'Green', 'Blue', 'Red']\n",
    "})\n",
    "\n",
    "data_cat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6fe5c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoded Data:\n",
      "   Color  Color_LabelEncoded\n",
      "0    Red                   2\n",
      "1   Blue                   0\n",
      "2  Green                   1\n",
      "3   Blue                   0\n",
      "4    Red                   2\n"
     ]
    }
   ],
   "source": [
    "# Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "data_cat['Color_LabelEncoded'] = label_encoder.fit_transform(data_cat['Color'])\n",
    "print(\"Label Encoded Data:\")\n",
    "print(data_cat)\n",
    "\n",
    "# fit_transform() in Label Encoding:\n",
    "# 1 fit(): It identifies the unique categories in the 'Color' feature and assigns each\n",
    "# a unique integer value.\n",
    "# 2 transform(): It replaces each category in the 'Color' feature with its corresponding integer value.\n",
    "# This is done in one step using fit_transform().   ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9730974",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09f21f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "One-Hot Encoded Data:\n",
      "   Color_Blue  Color_Green  Color_Red\n",
      "0       False        False       True\n",
      "1        True        False      False\n",
      "2       False         True      False\n",
      "3        True        False      False\n",
      "4       False        False       True\n"
     ]
    }
   ],
   "source": [
    "# One-Hot Encoding\n",
    "df = pd.DataFrame({  \n",
    "    'Color': ['Red', 'Blue', 'Green', 'Blue', 'Red']\n",
    "})\n",
    "\n",
    "data_onehot = pd.get_dummies(df, columns=['Color'], prefix='Color')\n",
    "print(\"\\nOne-Hot Encoded Data:\")\n",
    "print(data_onehot)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a66eae",
   "metadata": {},
   "source": [
    "### Label Encoder vs One-Hot Encoding\n",
    "\n",
    "LabelEncoder:\n",
    "- Use for: Target (y) only\n",
    "- Never use for Features (Creates false order)\n",
    "\n",
    "One-Hot (get_dummies)\n",
    "- Use for: Features (X) \n",
    "- Avoid when >15 categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4ff830",
   "metadata": {},
   "source": [
    "3. Normalization \n",
    "\n",
    "Normalize data such that row vector magnitudes = 1\n",
    "Why Use Normalizer?\n",
    "\n",
    "Purpose: Scales each row to have a unit magnitude (length = 1) while preserving direction.\n",
    "\n",
    "Key Idea: Converts row vectors into \"pure direction\" form by diving by Euclidean norm\n",
    "\n",
    "When to use?\n",
    "- Text data (TD-IDF, word counts)\n",
    "- Clustering (k-means, cosine similarity)\n",
    "- Any algorithm sensitive to vector magnitudes but not their lengths (e.g. NLP, recommender systems).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "199c7883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalized Data:\n",
      "[[0.8 0.2 0.4 0.4]\n",
      " [0.1 0.3 0.9 0.3]\n",
      " [0.5 0.7 0.5 0.1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "# Normalization\n",
    "X = np.array([[4, 1, 2, 2],\n",
    "              [1, 3, 9, 3],\n",
    "                [5, 7, 5, 1]])\n",
    "normalizer = Normalizer()\n",
    "X_normalized = normalizer.fit_transform(X)\n",
    "print(\"\\nNormalized Data:\")\n",
    "print(X_normalized)\n",
    "\n",
    "# How it works?\n",
    "# For each row, the normalizer computes the L2 norm (Euclidean norm) and divides each element in the row by this norm.\n",
    "# This scales each row to have a unit norm (length of 1).\n",
    "# Norm is calculated as: ||X|| = sqrt(x1^2 + x2^2 + ... + xn^2)\n",
    "# For example, for the first row [4, 1, 2, 2]:\n",
    "# L2 norm = sqrt(4^2 + 1^2 + 2^2 + 2^2) = sqrt(16 + 1 + 4 + 4) = sqrt(25) = 5\n",
    "# Normalized row = [4/5, 1/5, 2/5, 2/5] = [0.8, 0.2, 0.4, 0.4]\n",
    "# Normalization is particularly useful when you want to ensure that each data point (row) has equal weight in distance-based algorithms like KNN or clustering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d3cb16",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78313292",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
