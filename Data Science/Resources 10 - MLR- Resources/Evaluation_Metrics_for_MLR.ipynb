{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "519f893b",
   "metadata": {},
   "source": [
    "#### Common Evaluation Metrics for MLR\n",
    "\n",
    "1. R^^2 Score (Coefficient of Determination)\n",
    "- tells us what percentage of the variation in the target variable is explained by the model.\n",
    "- % variance explained\n",
    "- Ideal Value - Closer to 1.\n",
    "- Value lies between 0 and 1.\n",
    "- Use Case - Model fit quality.\n",
    "\n",
    "2. RMSE (Root Mean Squared Error)\n",
    "- lower the better.\n",
    "- Average squared error \n",
    "- Ideal Value- Closer to 0.\n",
    "- Use Case - Penalizes large errors.\n",
    "\n",
    "3. MAE (Mean Absolute Error)\n",
    "- Average absolute error \n",
    "- Ideal Value - Close to 0.\n",
    "- Simpler error interpretation.\n",
    "\n",
    "4. MAPE (Mean Absolute Percentage Error)\n",
    "- Average % error from actuals \n",
    "- Ideal Value - Lower% \n",
    "- Explaining % Error to audience.\n",
    "\n",
    "\n",
    "Notes: \n",
    "- Always evaluate the model on test data.\n",
    "- Use multiple metrics to get a complete picture.\n",
    "- RMSE penalizes large errors more; MAE is easier to explain\n",
    "- R^^2 shows explacatory power, not accuracy.\n",
    "\n",
    "Use these metrics to select and justify your regression model before making business decisions or deployment\n",
    "\n",
    "- A residual is the difference between actual value and the predicted value.\n",
    "- Residual value = Y actual - Y predicted\n",
    "\n",
    "### What does a good residual plot look like?\n",
    "- Residuals should be randomly scattered around the horizontal line at 0.\n",
    "- No clear pattern should be visible.\n",
    "- This means: your model's errors are evenly distributed - a sign of good fit.\n",
    "\n",
    "#### If residuals do not look random - \n",
    "- You may have missed a pattern in the data.\n",
    "- If residuals increase/ decrease systematically, it may mean: \n",
    "    - You are missing a nonlinear relationship.\n",
    "    - Your model may be underfitting or overfitting.\n",
    "\n",
    "\n",
    "#### If Residuals show a systematic Pattern - \n",
    "- A clear curve, slope, or funnel shape in the residuals means your model is violating key assumptions of linear regression - especially linearity and homoscedasticitity(constant variance).\n",
    "- This usually points to - \n",
    "    - A nonlinear relationship that linear regression con't capture\n",
    "    - Missing variables or interactions in the model.\n",
    "    - Possible underfitting.\n",
    "\n",
    "#### What can you do to fix it - \n",
    "- \n",
    "    1. Add Polynomial Terms - If the residuals follow a curved pattern (U-shared or inverted U), it means the relationsipt is nonlinear.\n",
    "    2. Apply Feature Transformation - \n",
    "        - If residuals increase or decrease systematically, apply tranformations like:\n",
    "             - log or sqrt for right-skewed variables.\n",
    "             - box cox for automatic transformation (scipy).\n",
    "    3. Add Missing Features or Interaction Terms\n",
    "        - Sometimes the model misses important variables or the interactions.\n",
    "    4. Use a more Flexible Model \n",
    "        - If linear regression is still struggling:\n",
    "            - Try Decision Trees, Random Forests, or Gradient Boosting.\n",
    "        - These handle nonlinearities and interactions automatically.\n",
    "    \n",
    "\n",
    "#### Note - \n",
    "- If your residuals show a curved pattern or increase with predictions, your model is likely missing something.\n",
    "- You can fix this by adding polynomial terms, transforming variables, or switching to noninear model.\n",
    "- Residual plots aren't just diagnostic - they guide how to improve the model.\n",
    "\n",
    "#### If the Residuals suggest Underfitting or Overfitting - \n",
    "- \n",
    "    1. Underfitting - \n",
    "        - Clues: Residuals show clear pattern (eg - curver, slope).\n",
    "        - R^^2 is low on both training and test sets.\n",
    "        - Model is too simple to capture true data structure.\n",
    "        - Commong Clauses: \n",
    "            - Using only linear terms when the relationship is nonlinear\n",
    "            - Leaving out important features.\n",
    "        - Remidies - \n",
    "            - Add polynomical features. (ex - degree 2/3)\n",
    "            - Include interaction terms\n",
    "            - Apply log/sqrt transformatioons.\n",
    "            - Switch to a more complex model.\n",
    "\n",
    "    2. Overfitting - \n",
    "        - Residuals look random on training data, but prediction errors are high on test data.\n",
    "        - High R^^2 on traning, low R^^2 on test data.\n",
    "        - Too many predictiors or overly complex model.\n",
    "        - Common Causes:\n",
    "            - Model memorizes notise instear of generating patters.\n",
    "        - Remedies:\n",
    "            - Simplify the model (remove unnecessary features).\n",
    "            - Use regularization: Tidge or Lasso Regresion.\n",
    "            - Apply cross-validation to detect overfitting early.\n",
    "            - Gather more data if possible.\n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84b985d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7131dc76",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
